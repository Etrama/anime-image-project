{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from tqdm import tqdm\n",
    "#scraping imports:\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import requests\n",
    "import cv2\n",
    "import os\n",
    "import ctypes\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import re\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = r\"./data/top_anime_list/UsableAnimeList.xlsx\"\n",
    "df = pd.read_excel(DATA, sheet_name=\"usable\")\n",
    "anime_list = df[\"usable_title\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scrapeAnimeImageURLs:\n",
    "    def __init__(self, anime_list):\n",
    "        self.downloads_folder = r\"C:\\Users\\kaush\\Downloads\"\n",
    "        self.img_urls_dest = r\"./data/anime_img_urls\"\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        self.options.add_argument('--headless=new')\n",
    "        self.driver = webdriver.Chrome(options=self.options)\n",
    "        for anime in tqdm(anime_list, desc=\"AnimeList\"):\n",
    "            self.img_dest_folder = \"./data/anime_images/\" + anime + \"/\"\n",
    "            self.get_image_URLS(anime)\n",
    "            url_filename = self.move_download_file(anime)\n",
    "            #even encoding = 'latin-1' will work\n",
    "            raw_image_urls= pd.read_csv(url_filename, encoding='ISO-8859-1', header=None)\n",
    "            raw_image_urls.columns = [\"image_tag\"]\n",
    "            processed_image_urls = raw_image_urls[\"image_tag\"].apply(self.get_url_from_html)\n",
    "            self.get_image_from_url(processed_image_urls, anime, self.img_dest_folder)\n",
    "        self.driver.quit()\n",
    "    \n",
    "    def get_image_URLS(self, anime_name):\n",
    "        print(f\"Currently scraping image urls for: {anime_name}\")\n",
    "        self.driver.get(\"https://www.google.com/search?tbm=isch&q=\" + anime_name)\n",
    "        for _ in range(1,9): #be mindful and increase the scroll range on each loop iteration\n",
    "            self.driver.execute_script(f\"window.scrollBy(0,{_*10000})\") # so its roughly 100 images per 10000 y-axis scroll\n",
    "            time.sleep(0.5) # of which a little less than half turn out to be useful\n",
    "        self.driver.execute_script(r\"\"\"\n",
    "            function saveImgTagToCSV(jsonArray) {\n",
    "            const csvData = jsonArray.map((element) => {\n",
    "                let imgTag = '';\n",
    "\n",
    "                if (element.outerHTML) {\n",
    "                imgTag = `\"${element.outerHTML.replace(/\"/g, '\"\"')}\"`;\n",
    "                }\n",
    "\n",
    "                return imgTag;\n",
    "            }).join('\\n');\n",
    "\n",
    "            return csvData;\n",
    "            }\n",
    "            //then run this:\n",
    "            const imgs_rg = Array.from(document.querySelectorAll('.rg_i'));\n",
    "            const imgs_grn = Array.from(document.querySelectorAll('.GRN7Gc'));\n",
    "            const imgs_ll = Array.from(document.querySelectorAll('.ll3EIMe'));\n",
    "            const imgs = imgs_rg.concat(imgs_grn, imgs_ll);\n",
    "            img_data = saveImgTagToCSV(imgs);\n",
    "            window.open('data:text/csv;charset=utf-8,' + escape(img_data))\"\"\")\n",
    "        \n",
    "    def move_download_file(self, anime_name):\n",
    "        time.sleep(1)\n",
    "        file_list = glob.glob(os.path.sep.join([self.downloads_folder, \"/*\"]))\n",
    "        latest_file = max(file_list, key=lambda x: os.stat(x).st_mtime)\n",
    "        self.created_filename = self.img_urls_dest+\"/\"+anime_name+\".csv\"\n",
    "        os.replace(latest_file, self.created_filename)\n",
    "        return self.created_filename\n",
    "\n",
    "    def get_url_from_html(self, html_code):   \n",
    "        match = re.search(r'<img.*?(?:src|data-src)=\"(.*?)\".*?>', html_code)\n",
    "        if match:\n",
    "            source = match.group(1)\n",
    "            return source #tested that this takes care of all cases.\n",
    "    \n",
    "    def get_image_from_url(self, url_sources, anime_name, dest_folder):\n",
    "        print(f\"Currently downloading images for: {anime_name}\")\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "        count = 0\n",
    "        for source in url_sources:\n",
    "            if source.startswith('data:image') and \"base64\" in source:\n",
    "                match = re.search(r'src=\"data:image\\/.*?;base64,(.*?)\"', source)\n",
    "                if match:\n",
    "                    base64_string = match.group(1)\n",
    "                    # Decode the base64 string\n",
    "                    image_data = base64.b64decode(base64_string)\n",
    "                    count += 1\n",
    "                    image_name = dest_folder + anime_name + \"_\" + str(count).zfill(3) + \".jpg\"\n",
    "                    with open(image_name, 'wb') as f:\n",
    "                        f.write(image_data)\n",
    "            else:\n",
    "                if \"favicon\" not in source:\n",
    "                    response = requests.get(source)\n",
    "                    # Check if the request was successful\n",
    "                    if response.status_code == 200:\n",
    "                        count += 1\n",
    "                        image_name = dest_folder + anime_name + \"_\" + str(count).zfill(3) + \".jpg\"\n",
    "                        # Open the file in binary mode and write the image content\n",
    "                        with open(image_name, 'wb') as file:\n",
    "                            file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AnimeList:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently scraping image urls for: cowboy bepop\n",
      "Currently downloading images for: cowboy bepop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AnimeList:  50%|█████     | 1/2 [00:39<00:39, 39.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently scraping image urls for: naruto\n",
      "Currently downloading images for: naruto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AnimeList: 100%|██████████| 2/2 [01:14<00:00, 37.02s/it]\n"
     ]
    }
   ],
   "source": [
    "scraper = scrapeAnimeImageURLs([\"cowboy bepop\", \"naruto\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    There are two kinds of image URLs in the image URLs file:\n",
    "        - base64 encoded image URLs\n",
    "        - normal image URLs\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Image classes:\n",
    "        rg_i Q4LuWd\n",
    "        GRN7Gc\n",
    "        ll3IMe.CBvy7c\n",
    "    Somehow we always have 0 LL images, but that's a worry for later....I'll keep it there just in case it works :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anime_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
