{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ### Imports:","metadata":{"execution":{"iopub.status.busy":"2023-06-10T21:10:41.786897Z","iopub.execute_input":"2023-06-10T21:10:41.787345Z","iopub.status.idle":"2023-06-10T21:10:41.817310Z","shell.execute_reply.started":"2023-06-10T21:10:41.787310Z","shell.execute_reply":"2023-06-10T21:10:41.816026Z"}}},{"cell_type":"code","source":"# standard imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n# torch\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Subset\nfrom torch.utils.data import DataLoader\n# from torchvision import datasets as torchV_datasets\n# I end up using the word datasets as a variable all the time\nimport torchvision\nfrom torchvision.io import read_image\nfrom torchvision import datasets as torchV_datasets\nfrom torchvision import transforms, utils\nfrom torchvision.utils import make_grid\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom torch.utils.data import Subset\nfrom torch import optim\n# from torchvision import datasets, transforms\nfrom tqdm.auto import tqdm\n# sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\n# others\nimport os\nimport shutil\nfrom distutils.dir_util import copy_tree\nimport glob as glob\n# import splitfolders #to split image data into train, val and test sets\nimport random\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimport collections\n# seeding\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:22:26.865995Z","iopub.execute_input":"2023-06-11T01:22:26.866982Z","iopub.status.idle":"2023-06-11T01:22:26.882120Z","shell.execute_reply.started":"2023-06-11T01:22:26.866917Z","shell.execute_reply":"2023-06-11T01:22:26.880998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Utility Class:\nThis class will move anime image folders from the dataset called anime-images-dataset to your local kaggle working directory.  \nFuture Work:\n- [ ] Add anime list based selection","metadata":{}},{"cell_type":"code","source":"class UtilityWorker():\n    \"\"\" \n    Utility class:\n        params:\n            num_anime: define number of anime to classify\n        notes:\n            - These will be randomly chosen\n            - Chosen anime are copied in the kaggle local working directory\n    \"\"\"\n    def __init__(self, num_anime, seed=42):\n        \"\"\"\n        Randomly choosing anime to copy to local working directory\n        \"\"\"\n        self.ANIME_IMAGES = \"../input/anime-images-dataset/data/anime_images/\"\n        self.INPUT = \"/kaggle/working/input/\"\n        # seed needs to be initialized before a call to random since threads can interfere with it\n        # https://towardsdatascience.com/random-seeds-and-reproducibility-933da79446e3\n        random.seed(seed)\n        animelist = random.sample(os.listdir(self.ANIME_IMAGES),k=num_anime)\n        # the copying operation may take upto 6-8 mins if you choose all the anime\n        print(f\"The anime chosen are: \\n{animelist}\")\n        # copying chosen anime from dataset to local working dir, in a folder called input\n        self.copy_folder_helper(animelist)             \n        print(f\"These anime can be found within folders of their own name in: {self.INPUT}\")\n        \n    def copy_folder_helper(self, animelist):\n        \"\"\"\n        Helper function that does the actual copying.\n        \"\"\"\n        for anime in animelist:\n            copy_tree(self.ANIME_IMAGES+anime, self.INPUT+anime)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:04:52.459340Z","iopub.execute_input":"2023-06-11T01:04:52.460271Z","iopub.status.idle":"2023-06-11T01:04:52.469223Z","shell.execute_reply.started":"2023-06-11T01:04:52.460233Z","shell.execute_reply":"2023-06-11T01:04:52.468257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utility = UtilityWorker(10, seed=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:04:52.471000Z","iopub.execute_input":"2023-06-11T01:04:52.471745Z","iopub.status.idle":"2023-06-11T01:05:10.618984Z","shell.execute_reply.started":"2023-06-11T01:04:52.471709Z","shell.execute_reply":"2023-06-11T01:05:10.618022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Class:\nWe define a data class that will create train and test split from the images in the kaggle local working directory.  \nWe don't need a validation split here since I am not bothered to tune hyperparameters right now.  \nThis class will also count the class instances in the splits.","metadata":{}},{"cell_type":"code","source":"class Data():\n    def __init__(self):\n        self.INPUT = \"/kaggle/working/input/\"\n        self.separator = \"#\"*80\n        \n    def get_full_dataset(self):\n        self.base_transforms = transforms.Compose([transforms.Resize((224, 224)),\n                                                   transforms.ToTensor(),])\n        self.full_dataset = torchV_datasets.ImageFolder(self.INPUT, transform=self.base_transforms)\n        print(f\"Full dataset details:\")\n        print(self.full_dataset)\n        print(self.separator)\n        return self.full_dataset\n    \n    def get_train_test_splits(self, dataset, test_split=0.20):\n        train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=test_split)\n        split_dataset = {}\n        split_dataset['train'] = Subset(dataset, train_idx)\n        split_dataset['val'] = Subset(dataset, val_idx)\n        train_dataset = split_dataset['train']\n        test_dataset = split_dataset['val']\n        print(f\"Size of the train dataset:{len(train_dataset)}\")\n        print(f\"Size of the test dataset:{len(test_dataset)}\")\n        print(self.separator)\n        return train_dataset, test_dataset\n    \n    def count_labels_in_dataset(self, dataset, dataset_name=\"optional\"):\n        labels = []\n        if dataset_name != \"optional\":\n            print(f\"Counting labels in {dataset_name} dataset....\")\n        else:\n            print(f\"Counting labels....\")\n        for _, label in tqdm(dataset):\n            labels.append(label)\n        print(f\"Label counts are:\\n{collections.Counter(labels)}\")\n        print(self.separator)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:10.621531Z","iopub.execute_input":"2023-06-11T01:05:10.622478Z","iopub.status.idle":"2023-06-11T01:05:10.632985Z","shell.execute_reply.started":"2023-06-11T01:05:10.622446Z","shell.execute_reply":"2023-06-11T01:05:10.632023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_obj = Data()\nfull_dataset = data_obj.get_full_dataset()\ntrain_dataset, test_dataset = data_obj.get_train_test_splits(full_dataset)\ndata_obj.count_labels_in_dataset(train_dataset, \"train\")\ndata_obj.count_labels_in_dataset(test_dataset, \"test\")","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:10.634385Z","iopub.execute_input":"2023-06-11T01:05:10.634800Z","iopub.status.idle":"2023-06-11T01:05:17.203532Z","shell.execute_reply.started":"2023-06-11T01:05:10.634770Z","shell.execute_reply":"2023-06-11T01:05:17.202617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting Images:\nThe following two functions were borrowed from this nice [tutorial](https://www.kaggle.com/code/shtrausslearning/pytorch-multiclass-image-classification#2-|-GET-THE-TRAINING-DATA).\nFuture Work:\n- [ ] Write our own image display function. Maybe one that's easier to read for me.\n- [ ] Include this in a class of its own??\n","metadata":{}},{"cell_type":"code","source":"# These functions have been borrowed as they are from:\n# https://www.kaggle.com/code/shtrausslearning/pytorch-multiclass-image-classification#2-|-GET-THE-TRAINING-DATA\ndef plot_img(img,y=None,color=True):\n    npimg = img.numpy()\n    npimg_T = np.transpose(npimg,(1,2,0))\n    plt.imshow(npimg_T)\n    plt.title('Image samples from each of the 10 classes')\n    plt.axis('on')\n\ndef plot_tensor(tensor,random_id=False,class_id=None):\n    \n    if(random_id is True):\n        rnd_inds = np.random.randint(0,len(tensor),100) \n        X_show = [tensor[i][0] for i in rnd_inds]\n        target = [tensor[i][1] for i in rnd_inds]\n    else:\n        \n        if(class_id is None):\n            X_show = []\n            # cycle through all classes\n            for j in range(0,10):\n                ii=-1\n                for i in range(0,1000):\n                    if(tensor[i][1] is j):\n                        ii+=1\n                        if(ii>19):\n                            break\n                        else:\n                            X_show.append(tensor[i][0])\n                        \n        if(class_id is not None):\n            \n            print(f'Showing samples from {len(tensor)} tensors:')\n            \n            X_show = []\n            ii=-1\n            for i in range(0,1000):\n                if(tensor[i][1] is class_id):\n                    ii+=1\n                    if(ii>19):\n                        break\n                    else:\n                        X_show.append(tensor[i][0])\n            \n            \n    X_grid = utils.make_grid(X_show,nrow=20,padding=1)\n    plt.figure(figsize=(30,10))\n    plot_img(X_grid,y=None,color=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:17.204979Z","iopub.execute_input":"2023-06-11T01:05:17.205766Z","iopub.status.idle":"2023-06-11T01:05:17.219935Z","shell.execute_reply.started":"2023-06-11T01:05:17.205733Z","shell.execute_reply":"2023-06-11T01:05:17.218878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_tensor(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:17.221618Z","iopub.execute_input":"2023-06-11T01:05:17.222014Z","iopub.status.idle":"2023-06-11T01:05:25.250818Z","shell.execute_reply.started":"2023-06-11T01:05:17.221983Z","shell.execute_reply":"2023-06-11T01:05:25.247032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_tensor(train_dataset,class_id=4)","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:25.252015Z","iopub.execute_input":"2023-06-11T01:05:25.253144Z","iopub.status.idle":"2023-06-11T01:05:26.481144Z","shell.execute_reply.started":"2023-06-11T01:05:25.253109Z","shell.execute_reply":"2023-06-11T01:05:26.480033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataloaders:\nCreating the train and test dataloaders in preparation for training.","metadata":{}},{"cell_type":"code","source":"train_transforms = transforms.Compose([transforms.RandomRotation(15),\n                                      transforms.Resize((232, 232)),\n                                      transforms.RandomVerticalFlip(p=0.5),\n                                      transforms.RandomHorizontalFlip(p=0.5),\n                                      transforms.ToTensor(),])\ntest_transforms = transforms.Compose([transforms.Resize((232, 232)),\n                                     transforms.ToTensor(),])\ntrain_dataset.transforms = train_transforms\ntest_dataset.transforms = test_transforms","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:26.482813Z","iopub.execute_input":"2023-06-11T01:05:26.483201Z","iopub.status.idle":"2023-06-11T01:05:26.490633Z","shell.execute_reply.started":"2023-06-11T01:05:26.483171Z","shell.execute_reply":"2023-06-11T01:05:26.489457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True) \ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\nx,y = next(iter(train_dataloader))\nprint(f\"Train batch data shapes:\\n{x.shape,y.shape}\")\nx,y = next(iter(test_dataloader))\nprint(f\"Test batch data shapes:\\n{x.shape,y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:26.494212Z","iopub.execute_input":"2023-06-11T01:05:26.494541Z","iopub.status.idle":"2023-06-11T01:05:26.633856Z","shell.execute_reply.started":"2023-06-11T01:05:26.494511Z","shell.execute_reply":"2023-06-11T01:05:26.632890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training:\nI will use a pretrained resnet50.  \nFuture Work: \n- [ ] I think the dataset could use some manual / automated cleaning and the results will probably be terrible, but this is meant to be a learning experience, so the results can be improved later.  \n- [ ] Manual cleaning would be a pain and automated cleaning would require a data pipeline since I mean to do the scraping periodically.","metadata":{}},{"cell_type":"code","source":"# list of models\n# https://pytorch.org/vision/stable/models.html\nmodel = resnet50(weights=\"IMAGENET1K_V2\")\n# we need to preprocess our batch in (B, C, H, W) form according to way ImageNet was pre-processed\n# we can use the preprocess defined below on a batch now as a function: preprocess(batch)\npreprocess = ResNet50_Weights.IMAGENET1K_V2.transforms()\n# we need to fix the final out_features / number of classes in the fully connected layer at the end of the resnet\nprint(f\"ImageNet Defaults: {model.fc}\")\nfc_inputs = model.fc.in_features\nmodel.fc = nn.Sequential(\n    nn.Linear(fc_inputs, 256),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(256, 10), #10 is num_classes\n    nn.LogSoftmax(dim=1) # For using NLLLoss()\n)\nmodel = model.to(device)\nprint(f\"After update: {model.fc}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:26.636028Z","iopub.execute_input":"2023-06-11T01:05:26.636608Z","iopub.status.idle":"2023-06-11T01:05:31.414085Z","shell.execute_reply.started":"2023-06-11T01:05:26.636575Z","shell.execute_reply":"2023-06-11T01:05:31.413080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_run(model=model, valid_loader=test_dataloader, device=device):\n    with torch.no_grad():\n        model.eval()\n        labels = torch.tensor([])\n        predictions = torch.tensor([])\n        model.eval()\n        valid_loss = 0.0\n        for inputs, labels in tqdm(valid_loader, desc=\"Valid\"):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs) #log probs\n            predicted_class = outputs.argmax(dim=1)\n            loss = criterion(outputs, labels)\n            valid_loss += loss.item() #explore when we multiply this by input size, probably when reduction = sum?\n            valid_accuracy = 100*accuracy_score(labels.detach().cpu(), predicted_class.detach().cpu())\n        return valid_loss, valid_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:31.415566Z","iopub.execute_input":"2023-06-11T01:05:31.416367Z","iopub.status.idle":"2023-06-11T01:05:31.424493Z","shell.execute_reply.started":"2023-06-11T01:05:31.416334Z","shell.execute_reply":"2023-06-11T01:05:31.423574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.NLLLoss(reduction=\"mean\")\noptimizer = optim.Adam(model.parameters())\nepochs = 25","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:31.426053Z","iopub.execute_input":"2023-06-11T01:05:31.429173Z","iopub.status.idle":"2023-06-11T01:05:31.452693Z","shell.execute_reply.started":"2023-06-11T01:05:31.429142Z","shell.execute_reply":"2023-06-11T01:05:31.451704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(epochs=epochs, model=model, train_dataloader=train_dataloader, device=device):\n    train_losses = []\n    train_accuracies = []\n    valid_losses = []\n    valid_accuracies = []\n    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n        model.train()\n        train_loss, train_accuracy = 0.0, 0.0\n        valid_loss, valid_accuracy = 0.0, 0.0\n        for inputs, labels in tqdm(train_dataloader, desc=\"Train\"):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs) #log probs\n            predicted_class = outputs.argmax(dim=1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() #explore when we multiply this by input size, probably when reduction = sum?\n            train_accuracy = 100*accuracy_score(labels.detach().cpu(), predicted_class.detach().cpu())\n        print(f\"Epoch {epoch}, Training Loss: {train_loss}, Training Accuracy: {train_accuracy}\")\n        valid_loss, valid_accuracy = eval_run()\n        print(f\"Epoch {epoch}, Test Loss: {valid_loss}, Test Accuracy: {valid_accuracy}\")\n        train_losses.append(train_loss)\n        train_accuracies.append(train_accuracy)\n        valid_losses.append(valid_loss)\n        valid_accuracies.append(valid_accuracy)\n    return train_losses, train_accuracies, valid_losses, valid_accuracies","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:31.454159Z","iopub.execute_input":"2023-06-11T01:05:31.454480Z","iopub.status.idle":"2023-06-11T01:05:31.464877Z","shell.execute_reply.started":"2023-06-11T01:05:31.454451Z","shell.execute_reply":"2023-06-11T01:05:31.463883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses, train_accuracies, valid_losses, valid_accuracies = train()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:05:31.466316Z","iopub.execute_input":"2023-06-11T01:05:31.466815Z","iopub.status.idle":"2023-06-11T01:15:54.636078Z","shell.execute_reply.started":"2023-06-11T01:05:31.466778Z","shell.execute_reply":"2023-06-11T01:15:54.635016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_dir = \"/kaggle/working/models/\"\nif not os.path.exists(save_dir):\n    os.makedirs(save_dir)\ntorch.save(model.state_dict(), save_dir+\"trained_resnet50_25epochs.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:17:52.875228Z","iopub.execute_input":"2023-06-11T01:17:52.875611Z","iopub.status.idle":"2023-06-11T01:17:53.033129Z","shell.execute_reply.started":"2023-06-11T01:17:52.875584Z","shell.execute_reply":"2023-06-11T01:17:53.032175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting curves:","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2)\nfig.set_size_inches(15, 7.5)\nfig.suptitle(\"Train-Test Losses and Accuracies\")\ntrain_losses, train_accuracies, valid_losses, valid_accuracies\nx = [e for e in range(epochs)]\nax1.set_title(\"Loss vs. Epochs\")\nax1.plot(x, train_losses, label=\"Train Loss\")\nax1.plot(x, valid_losses, label=\"Valid Loss\")\nax1.legend()\nax1.set_xticks(x)\nax2.set_title(\"Accuracy vs. Epochs\")\nax2.plot(x, train_accuracies, label=\"Train Accuracy\")\nax2.plot(x, valid_accuracies, label=\"Valid Accuracy\")\nax2.set_xticks(x)\nax2.legend()","metadata":{"execution":{"iopub.status.busy":"2023-06-11T01:22:53.742781Z","iopub.execute_input":"2023-06-11T01:22:53.743166Z","iopub.status.idle":"2023-06-11T01:22:55.055712Z","shell.execute_reply.started":"2023-06-11T01:22:53.743136Z","shell.execute_reply":"2023-06-11T01:22:55.054860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There seems to be some overfitting for sure based on the loss curves.  \nBut despite the dataset problems and the lack of a learning rate scheduler and hyperparameter search, we still get around 70% accuracy on the validation set, which is cool.","metadata":{}},{"cell_type":"markdown","source":"### TO DO LATER:\n    - Make everything object oriented\n    - Train a large resnet from scratch\n    - Try different models\n    - Plot curves while training itself so we can monitor easily and avoid useless runs\n    - Other applications of this dataset.","metadata":{"execution":{"iopub.status.busy":"2023-06-04T16:48:25.818845Z","iopub.execute_input":"2023-06-04T16:48:25.819184Z","iopub.status.idle":"2023-06-04T16:48:25.825309Z","shell.execute_reply.started":"2023-06-04T16:48:25.819162Z","shell.execute_reply":"2023-06-04T16:48:25.823823Z"}}},{"cell_type":"markdown","source":"### References:\n    - https://www.kaggle.com/code/leifuer/intro-to-pytorch-loading-image-data\n    - https://discuss.pytorch.org/t/how-to-split-dataset-into-test-and-validation-sets/33987/5\n    - https://www.kaggle.com/code/shtrausslearning/pytorch-multiclass-image-classification#2-|-GET-THE-TRAINING-DATA\n    - https://learnopencv.com/image-classification-using-transfer-learning-in-pytorch/","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}